{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Imports\n",
    "import torch\n",
    "import torch.nn  as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "#Load fake, non handwritten generator \n",
    "from IAM_dataset import hwrDataset as Dataset\n",
    "#Import the loss from baidu \n",
    "from torch_baidu_ctc import CTCLoss\n",
    "\n",
    "#Import the model \n",
    "from fully_conv_model import cnn_attention_ocr\n",
    "\n",
    "#Helper to count params\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "#Evaluation function preds_to_integer\n",
    "from evaluation import wer_eval,preds_to_integer,show,AverageMeter,my_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up Tensorboard writer for current test\n",
    "writer = SummaryWriter(log_dir=\"/home/leander/AI/repos/Pytorch-OCR-Fully-Conv//logs2/handwritten_test_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3543584"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Set up model. \n",
    "cnn=cnn_attention_ocr(model_dim=64,nclasses=93,n_layers=8)\n",
    "cnn=cnn.cuda().train()\n",
    "count_parameters(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CTC Loss \n",
    "ctc_loss = CTCLoss(reduction=\"mean\",average_frames=True)\n",
    "#Optimizer: Good initial is 5e5 \n",
    "optimizer = optim.Adam(cnn.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We keep track of the Average loss and CER \n",
    "ave_total_loss = AverageMeter()\n",
    "CER_total= AverageMeter()\n",
    "\n",
    "n_iter=0\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.load_state_dict(torch.load(\"8_layers_continued_on_blanks_340k.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds=Dataset()\n",
    "trainset = DataLoader(dataset=ds,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leander/AI/repos/Pytorch-OCR-Fully-Conv/evaluation.py:42: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return we/len(preds)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9cd07fc0c221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mwer_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mwer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwer_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m#Here we save an example together with its decoding and truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/repos/Pytorch-OCR-Fully-Conv/evaluation.py\u001b[0m in \u001b[0;36mwer_eval\u001b[0;34m(preds, labels)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwer_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mwe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwe\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/repos/Pytorch-OCR-Fully-Conv/evaluation.py\u001b[0m in \u001b[0;36mwer\u001b[0;34m(r, h)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0msubstitution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0minsertion\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mdeletion\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epochs in range(10000):\n",
    "\n",
    "    #Then we set up our own custom dataloade500r, with a custom collate, which packs the data\n",
    "    #(does the padding) Should work with variable number of widths. \n",
    "    \n",
    "    #Multiple worker leads to crash with CTC loss \n",
    "\n",
    "    gen = iter(trainset)\n",
    "    print(\"train start\")\n",
    "    for i,ge in enumerate(gen):\n",
    "        \n",
    "        if ge[0].shape[3]<=800:\n",
    "\n",
    "            #DONT FORGET THE ZERO GRAD!!!!\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Get Predictions, permuted for CTC loss \n",
    "            log_probs = cnn(ge[0]).permute((2,0,1))\n",
    "\n",
    "            #Targets have to be CPU for baidu loss \n",
    "            targets = ge[1].cpu()\n",
    "\n",
    "            #Get the Lengths/2 becase this is how much we downsample the width\n",
    "            input_lengths = ge[2]/2\n",
    "            target_lengths = ge[3]\n",
    "            \n",
    "            #Get the CTC Loss \n",
    "            loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "            \n",
    "            #Then backward and step \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Save Loss in averagemeter and write to tensorboard \n",
    "            ave_total_loss.update(loss.data.item())\n",
    "            writer.add_scalar(\"total_loss\", ave_total_loss.average(), n_iter) \n",
    "            \n",
    "            \n",
    "            #Here we Calculate the Character error rate\n",
    "            cum_len=np.cumsum(target_lengths)\n",
    "            targets=np.split(ge[1].cpu(),cum_len[:-1])\n",
    "            wer_list=[]\n",
    "            for j in range(log_probs.shape[1]):\n",
    "                wer_list.append(wer_eval(log_probs[:,j,:][0:input_lengths[j],:],targets[j]))\n",
    "            \n",
    "            #Here we save an example together with its decoding and truth\n",
    "            #Only if it is positive \n",
    "            \n",
    "            if np.average(wer_list)>0.1 and n_iter> 10000:\n",
    "\n",
    "                max_elem=np.argmax(wer_list)\n",
    "                max_value=np.max(wer_list)\n",
    "                max_image=ge[0][max_elem].cpu()\n",
    "                max_target=targets[max_elem]\n",
    "                \n",
    "                max_target=[ds.decode_dict[x] for x in max_target.tolist()]\n",
    "                max_target=\"\".join(max_target)\n",
    "\n",
    "                ou=preds_to_integer(log_probs[:,max_elem,:])\n",
    "                max_preds=[ds.decode_dict[x] for x in ou]\n",
    "                max_preds=\"\".join(max_preds)\n",
    "                \n",
    "                writer.add_text(\"label\",max_target,n_iter)\n",
    "                writer.add_text(\"pred\",max_preds,n_iter)\n",
    "                writer.add_image(\"img\",ge[0][max_elem].detach().cpu().numpy(),n_iter)\n",
    "                \n",
    "                #gen.close()\n",
    "                #break\n",
    "                \n",
    "            #Might become infinite \n",
    "            if np.average(wer_list)< 10: \n",
    "                CER_total.update(np.average(wer_list))\n",
    "                writer.add_scalar(\"CER\", CER_total.average(), n_iter)\n",
    "                \n",
    "            n_iter=n_iter+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorchenv)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
